.. _write-operations-bulk-insert:

================================
Bulk Write Operations in MongoDB
================================

.. default-domain:: mongodb

Overview
--------

MongoDB provides an interface that allows clients to specify write
operations in groups. A protocol also integrates write operations
with write concerns to allow applications to determine the acceptable
level of acknowledgement required of bulk operations.

Bulk Operations
~~~~~~~~~~~~~~~

The :method:`Bulk()` operations builder constructs a list of operations to
perform in bulk for a single collection.

Bulk write operations are **ordered** or **unordered**:

- Ordered bulk operations use the
  :method:`db.collection.initializeOrderedBulkOp()` method to initialize a
  list of write operations serially. If an error occurs during the
  processing of one of the write operations, MongoDB will return without
  processing any remaining write operations in the list.

- Unordered bulk operations use the
  :method:`db.collection.initializeUnorderedBulkOp()` method to execute a
  list of write operations in parallel or in nondeterministic order. If an
  error occurs during the processing of one of the write operations,
  MongoDB will continue to process remaining write operations in the list.

The ordered or unordered type of bulk operations also affects the
execution order. For example, if an ordered list has two insert operations
followed by an update operation then another insert operation, MongoDB
groups the operations into three separate groups: the first group contains
the two insert operations, the second group contains the update operation,
and the third group contains the last insert operation.

With an unordered bulk operation, the operations in the list may be
reordered by MongoDB to increase performance. As such, applications should
not depend on the ordering when performing unordered bulk operations.

See :method:`Bulk.execute()` for more information about bulk execution
order.

Bulk Commands
~~~~~~~~~~~~~

MongoDB also provides the :dbcommand:`insert`, :dbcommand:`update`, and
:dbcommand:`delete` commands, which provide the basis for the improved
bulk operations functionality. All officially supported MongoDB drivers
support these new commands.

See :method:`Bulk()`, :doc:`/reference/method/js-bulk`,
:doc:`/core/write-operations-introduction`, and
:ref:`write-methods-incompatibility` for more information about new
methods to perform bulk-write operations.

.. TODO: section on general write operation considerations?

Limits
~~~~~~

.. include:: /includes/fact-bulk-operation-batches.rst

Examples
--------

Bulk Insert
~~~~~~~~~~~

The following initializes a :method:`Bulk()` operations builder for the
``items`` collection, adds a series of insert operations to add
multiple documents:

.. code-block:: javascript

   var bulk = db.items.initializeOrderedBulkOp();
   bulk.insert( { _id: 1, item: "abc123", status: "A", soldQty: 5000 } );
   bulk.insert( { _id: 2, item: "ijk123", status: "A", soldQty: 150 } );
   bulk.insert( { _id: 3, item: "mop123", status: "U", soldQty: 0 } );
   bulk.insert( { _id: 4, item: "qrs123", status: "U", soldQty: 70 } );
   bulk.execute();

The :method:`Bulk()` method returns a :method:`BulkWriteResult` object
that contains the result of the operation:

.. code-block:: javascript

   BulkWriteResult({
      "writeErrors" : [ ],
      "writeConcernErrors" : [ ],
      "nInserted" : 4,
      "nUpserted" : 0,
      "nMatched" : 0,
      "nModified" : 0,
      "nRemoved" : 0,
      "upserted" : [ ]
   })

For details on the return object, see :method:`BulkWriteResult()`. For
details on the batches executed, see :method:`Bulk.getOperations()`.

The following inserts documents into the ``items`` collection with
:method:`db.runCommand()`:

.. code-block:: javascript

   db.runCommand(
      {
         insert: "items",
         documents: [
            { _id: 1, item: "abc123", status: "A", soldQty: 5000 },
            { _id: 2, item: "ijk123", status: "A", soldQty: 150 },
            { _id: 3, item: "mop123", status: "U", soldQty: 0 },
            { _id: 4, item: "qrs123", status: "U", soldQty: 70 }
         ],
         ordered: true,
         writeConcern: { w: "majority", wtimeout: 5000 }
      }
   )

The returned document shows the command successfully inserted the
documents. See :ref:`insert-command-output` for details.

.. code-block:: javascript

   { "ok" : 1, "n" : 4 }

Bulk Update
~~~~~~~~~~~

The following example initializes a :method:`Bulk()` operations builder
for the ``items`` collection and adds two update operations. The update
operations use the :method:`Bulk.find()` method to specify a condition
for their respective actions:

.. code-block:: javascript

   var bulk = db.items.initializeUnorderedBulkOp();
   bulk.find( { item: "qrs123" } ).update( { $set: { soldQty: 700 } } )
   bulk.find( { soldQty: { $lte: 500 } } ).update( { $set: { status: "X" } } )
   bulk.execute();

The :method:`Bulk()` method returns a :method:`BulkWriteResult` object
that contains the result of the operation:

.. code-block:: javascript

   BulkWriteResult({
      "writeErrors" : [ ],
      "writeConcernErrors" : [ ],
      "nInserted" : 0,
      "nUpserted" : 0,
      "nMatched" : 3,
      "nModified" : 3,
      "nRemoved" : 0,
      "upserted" : [ ]
   })

The following example performs multiple update operations on the
``items`` collection with :method:`db.runCommand()`:

.. code-block:: javascript

   db.runCommand(
      {
         update: "items",
         updates: [
            { q: { item: "qrs123" }, u: { $set: { soldQty: 700 } }, multi: true },
            { q: { soldQty: { $lte: 500 } }, u: { $set: { status: "X" } }, multi: true },
         ],
         ordered: true,
         writeConcern: { w: "majority", wtimeout: 5000 }
      }
   )

The returned document shows the result of the operation. See
:ref:`update-command-output` for details.

.. code-block:: javascript

   { "ok" : 1, "nModified" : 3, "n" : 3 }

Bulk Delete
~~~~~~~~~~~

The :method:`Bulk.find.remove()` method removes all matching documents in
a collection. To limit the remove to a single document, see
:method:`Bulk.find.removeOne()`.

The following operations initializes a :method:`Bulk()` operations builder
for the ``items`` collection and adds a remove operation to the list of
operations:

.. code-block:: javascript

   var bulk = db.items.initializeOrderedBulkOp();
   bulk.find( { status: "X" } ).remove();
   bulk.find( { soldQty: { $lte: 1000 } } ).remove();
   bulk.execute();
   bulk.getOperations();

The :method:`Bulk()` method returns a :method:`BulkWriteResult` object
that contains the result of the operation.

.. code-block:: javascript

   BulkWriteResult({
      "writeErrors" : [ ],
      "writeConcernErrors" : [ ],
      "nInserted" : 0,
      "nUpserted" : 0,
      "nMatched" : 0,
      "nModified" : 0,
      "nRemoved" : 3,
      "upserted" : [ ]
   })

The following operation deletes a group of documents from the ``items``
collection with :method:`db.runCommand()`:

.. code-block:: javascript

   db.runCommand(
      {
         delete: "items",
         deletes: [
            { q: { status: "X" }, limit: 1 },
            { q: { soldQty: { $lte: 1000 } }, limit: 1 },
         ],
         ordered: true,
         writeConcern: { w: 1 }
      }
   )

The returned document shows the result of the operation. See
:ref:`delete-command-output` for details.

.. code-block:: javascript

   { "ok" : 1, "n" : 3 }

Bulk Inserts on Sharded Clusters
--------------------------------

While ``ContinueOnError`` is optional on unsharded clusters, all bulk
operations to a :term:`sharded collection <sharded cluster>` do not run
with ``ContinueOnError``, which cannot be disabled.

Large bulk insert operations, including initial data inserts or routine
data import, can affect :term:`sharded cluster` performance. For
bulk inserts, consider the following strategies:

Pre-Split the Collection
~~~~~~~~~~~~~~~~~~~~~~~~

If the sharded collection is empty, then the collection has only
one initial :term:`chunk`, which resides on a single shard.
MongoDB must then take time to receive data, create splits, and
distribute the split chunks to the available shards. To avoid this
performance cost, you can pre-split the collection, as described in
:doc:`/tutorial/split-chunks-in-sharded-cluster`.

Insert to Multiple ``mongos``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To parallelize import processes, send insert operations to more than
one :program:`mongos` instance. Pre-split empty collections first as
described in :doc:`/tutorial/split-chunks-in-sharded-cluster`.

Avoid Monotonic Throttling
~~~~~~~~~~~~~~~~~~~~~~~~~~

If your shard key increases monotonically during an insert, then all
inserted data goes to the last chunk in the collection, which will
always end up on a single shard. Therefore, the insert capacity of the
cluster will never exceed the insert capacity of that single shard.

If your insert volume is larger than what a single shard can process,
and if you cannot avoid a monotonically increasing shard key, then
consider the following modifications to your application:

- Reverse the binary bits of the shard key. This preserves the
  information and avoids correlating insertion order with increasing
  sequence of values.

- Swap the first and last 16-bit words to "shuffle" the inserts.

.. example:: The following example, in C++, swaps the leading and
   trailing 16-bit word of :term:`BSON` :term:`ObjectIds <ObjectId>`
   generated so they are no longer monotonically increasing.

   .. code-block:: cpp

      using namespace mongo;
      OID make_an_id() {
        OID x = OID::gen();
        const unsigned char *p = x.getData();
        swap( (unsigned short&) p[0], (unsigned short&) p[10] );
        return x;
      }

      void foo() {
        // create an object
        BSONObj o = BSON( "_id" << make_an_id() << "x" << 3 << "name" << "jane" );
        // now we may insert o into a sharded collection
      }

.. seealso:: :ref:`sharding-shard-key` for information
   on choosing a sharded key. Also see :ref:`Shard Key
   Internals <sharding-internals-shard-keys>` (in particular,
   :ref:`sharding-internals-operations-and-reliability`).
